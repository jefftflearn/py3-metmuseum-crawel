{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "metmuseumCrawel.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jefftflearn/py3-metmuseum-crawel/blob/master/metmuseumCrawel.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "zKEDGx3FD9b-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "322ac774-2e87-4aec-b2b9-b58f24efdf9c"
      },
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pip 10.0.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\r\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SuwDBubAESQn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "import urllib\n",
        "import ssl\n",
        "from bs4 import BeautifulSoup\n",
        "from time import sleep\n",
        "import os\n",
        "import json\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "def readHtmlSourceCode(url):\n",
        "  response = urllib.request.urlopen(url)\n",
        "  srcCode = response.read()\n",
        "  return srcCode\n",
        "\n",
        "def downloadImageFromUrlThenUpload(driver, imgUrl, title):\n",
        "  fname = title.replace(\" \", \"_\").replace(\";\", \"#\").replace(\",\", \"##\").replace(\"(\", \"$\").replace(\")\", \"$\")\n",
        "  path = './' + title.replace(\" \", \"_\").replace(\";\", \"#\").replace(\",\", \"##\").replace(\"(\", \"$\").replace(\")\", \"$\")\n",
        "  try:\n",
        "    response = urllib.request.urlopen(imgUrl)\n",
        "    file = open(path, \"wb\")\n",
        "    file.write(response.read())\n",
        "    file.close()\n",
        "    uploaded = drive.CreateFile({'title': fname})\n",
        "    #uploaded.SetContentString(response.read())\n",
        "    uploaded.SetContentFile(path)\n",
        "    uploaded.Upload()\n",
        "    print('upload success '+fname);\n",
        "    os.remove(path)\n",
        "    print('remove temp file completed')\n",
        "  except urllib.error.HTTPError as err:\n",
        "    print(\"404 not found\")\n",
        "  \n",
        "def uploadCsvFile(driver, str):\n",
        "  uploaded = drive.CreateFile({'title': 'metmuseum_'+q+\".txt\"})\n",
        "  uploaded.SetContentString(str)\n",
        "  uploaded.Upload()\n",
        "  print(\"upload db index file success\")\n",
        "  \n",
        "ssl._create_default_https_context=ssl._create_unverified_context\n",
        "  \n",
        "keywords = 'Generative Adversarial Nets'\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "print('接入google drive')\n",
        "\n",
        "token = 'https://images.metmuseum.org/CRDImages/'\n",
        "perPage = 20\n",
        "offset = 1\n",
        "\n",
        "q = 'Raffaello%20Sanzio'\n",
        "i = 0\n",
        "count = 0\n",
        "csvStr = ''\n",
        "while count < 9:\n",
        "  offset = perPage * i + 1\n",
        "  url = 'https://www.metmuseum.org/api/collection/collectionlisting?artist=&department=&era=&geolocation=&material=&offset='+str(offset)+'&pageSize=0&perPage='+str(perPage)+'&q='+q+'&showOnly=&sortBy=Relevance&sortOrder=asc'\n",
        "\n",
        "  html = readHtmlSourceCode(url)\n",
        "  jsObj = json.loads(html)\n",
        "  dataset = jsObj['results']\n",
        "  request = jsObj['request']\n",
        "  i += 1\n",
        "  if len(dataset) != 0 :\n",
        "    \n",
        "    print(\"==============================================================================================================offset: \"+str(offset))\n",
        "\n",
        "    for item in dataset[:] :\n",
        "      orginImage = item['largeImage'].replace('web-large', 'original')\n",
        "      orginImageUrl = token + orginImage\n",
        "      if 'noimage' not in orginImageUrl:\n",
        "        print(item)\n",
        "        medium = item['medium']\n",
        "        description = item['description']\n",
        "        title = item['title']\n",
        "        downloadImageFromUrlThenUpload(drive, orginImageUrl, title)\n",
        "        csvStr += title + \" $$$$ \" + description + \" $$$$ \" + medium + \" $$$$ \" + orginImageUrl + \"\\r\\n\"\n",
        "        #print(orginImageUrl)\n",
        "  else:\n",
        "    break\n",
        "  count += 1\n",
        "uploadCsvFile(drive, csvStr)\n",
        "print(count)\n",
        "    \n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}